params {
    sample_sheet = null
    ref_fasta = null
    ref_cn_xx = null
    ref_cn_xy = null
    outdir = null

    // Max resource options
    max_cpus = 36
    max_memory = 180.GB
    max_time = 28.d
}

cleanup = false

process {
    // Capture exit codes from upstream processes when piping
    shell = ['/bin/bash', '-euo', 'pipefail']

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries = 1
    maxErrors = -1

    withName: 'SAWFISH' {
        container = "community.wave.seqera.io/library/sawfish:0.12.8--40c29d979c4a1977"
        cpus = { check_max( 16, 'cpus' ) }
        memory = { check_max( 128.GB * task.attempt, 'memory') }
        time = { check_max( 3.h  * task.attempt, 'time') }
        publishDir = [
            path: params.outdir,
            mode: 'move'
        ]
    }
}

// Capture Nextflow log files
timeline {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_timeline.html"
}
report {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_report.html"
}
trace {
    enabled = true
    file = "${params.outdir}/pipeline_info/execution_trace.txt"
}
dag {
    enabled = true
    file = "${params.outdir}/pipeline_info/pipeline_dag.svg"
}

profiles {
    debug {
        dumpHashes = true
        process.beforeScript = 'echo $HOSTNAME'
        cleanup = false
        nextflow.enable.configProcessNamesValidation = true
    }
    docker {
        docker.enabled = true
        singularity.enabled = false
        apptainer.enabled = false
        docker.runOptions = '-u $(id -u):$(id -g)'
    }
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        docker.enabled = false
        apptainer.enabled = false
    }
    apptainer {
        apptainer.enabled = true
        apptainer.autoMounts = true
        docker.enabled = false
        singularity.enabled = false
    }
    mccleary {
        apptainer {
            enabled = true
            autoMounts = true
        }

        executor {
            name = 'slurm'
            queueSize = 40
            submitRateLimit = '200/60min'
        }

        process {
            resourceLimits = [
                cpus: 36,
                memory: 180.GB,
                time: 28.d
            ]
            executor = 'slurm'
            queue = 'pi_hall'
            clusterOptions = '--constraint=nogpu'
        }
    }
}

// Function to ensure that resource requirements don't go beyond a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
